{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romenlaw/RL-playground/blob/main/rl_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/mimoralea/gym-walk#egg=gym-walk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TXRzOQR4kYX",
        "outputId": "641e4f95-0b71-46bd-e1c4-13f8b9f6c85d"
      },
      "id": "8TXRzOQR4kYX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym-walk\n",
            "  Cloning https://github.com/mimoralea/gym-walk to /tmp/pip-install-4crz1g2k/gym-walk_7189d96af84c406e976a99dcc3a1f8f7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mimoralea/gym-walk /tmp/pip-install-4crz1g2k/gym-walk_7189d96af84c406e976a99dcc3a1f8f7\n",
            "  Resolved https://github.com/mimoralea/gym-walk to commit 5999016267d6de2f5a63307fb00dfd63de319ac1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from gym-walk) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-walk) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-walk) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->gym-walk) (0.0.8)\n",
            "Building wheels for collected packages: gym-walk\n",
            "  Building wheel for gym-walk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym-walk: filename=gym_walk-0.0.2-py3-none-any.whl size=4058 sha256=cf79ee378dcb8f6892108f4b67561055d812b6a7afcc71c3f46d8fd2b2f1e484\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mbvta0yw/wheels/24/fe/c4/0cbc7511d29265bad7e28a09311db3f87f0cafba74af54d530\n",
            "Successfully built gym-walk\n",
            "Installing collected packages: gym-walk\n",
            "Successfully installed gym-walk-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym, gym_walk\n",
        "import warnings\n",
        "\n",
        "# Ignore all DeprecationWarning\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "lPaUdewi3ncY"
      },
      "id": "lPaUdewi3ncY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MDP Concepts / Foundation\n",
        "Markov Decision Process:\n",
        "* Partially-Observable Markov Decision Process (POMDP): When the agent cannot fully observe the environment state.\n",
        "* Factored Markov Decision Process (FMDP): Allows the representation of the transition and reward function more compactly so that we can represent very large MDPs.\n",
        "* Continuous [Time|Action|State] Markov Decision Process: When either time, action, state or any combination of them are continuous.\n",
        "* Relational Markov Decision Process (RMDP): Allows the combination of probabilistic and relational knowledge.\n",
        "* Semi-Markov Decision Process (SMDP): Allows the inclusion of abstract actions that can take multiple time steps to complete.\n",
        "* Multi-Agent Markov Decision Process (MMDP): Allows the inclusion of multiple agents in the same environment.\n",
        "* Decentralized Markov Decision Process (Dec-MDP): Allows for multiple agents to collaborate and maximize a common reward.\n",
        "\n",
        "$MDP(\\mathcal S,\\mathcal A,\\mathcal T,\\mathcal R, \\mathcal S_{\\theta}, \\gamma, \\mathcal H)$\n",
        "\n",
        "$POMDP(\\mathcal S,\\mathcal A,\\mathcal T,\\mathcal R, \\mathcal S_{\\theta}, \\gamma, \\mathcal H, \\mathcal O, \\mathcal E)$\n",
        "\n",
        "$\\mathcal S$ is state space,\n",
        "$\\mathcal A$ is action space,\n",
        "$\\mathcal T$ is transition function,\n",
        "$\\mathcal R$ is reward signal,\n",
        "$\\mathcal S_{\\theta}$ is initial states distribution,\n",
        "$\\gamma$ is discount factor,\n",
        "$\\mathcal H$ is horizon,\n",
        "$\\mathcal O$ is observation space,\n",
        "$\\mathcal E$ is emission probability that defines the prob of showing an observation $o_t$ at given state $s_t$.\n",
        "\n"
      ],
      "metadata": {
        "id": "6Tk0Fht_8BEY"
      },
      "id": "6Tk0Fht_8BEY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment\n",
        "* The outer dict keys are States.\n",
        "* The inner dict keys are Actions.\n",
        "\n",
        "{0: {0: [(0.8, 0, 0.0, True), ...], ...\n",
        "\n",
        "In State 0, Action 0 has 80% chance to transit into State 0, which has Reward 0.0 and is a terminal state..."
      ],
      "metadata": {
        "id": "TH17Y7MJ5p2W"
      },
      "id": "TH17Y7MJ5p2W"
    },
    {
      "cell_type": "code",
      "source": [
        "P = gym.make('BanditSlipperyWalk-v0').env.P\n",
        "print(f\"this environment has {len(P)} states\")\n",
        "print(f\"state 1 has transition rules: Action: [(prob, next_state, reward, next_state_is_terminal), (...), ...]: \\n\", P[1])\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfRXIV4K3vTG",
        "outputId": "ae887191-731c-460a-ebe0-da805aef5a5e"
      },
      "id": "hfRXIV4K3vTG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this environment has 3 states\n",
            "state 1 has transition rules: Action: [(prob, next_state, reward, next_state_is_terminal), (...), ...]: \n",
            " {0: [(0.8, 0, 0.0, True), (0.0, 1, 0.0, False), (0.2, 2, 1.0, True)], 1: [(0.8, 2, 1.0, True), (0.0, 1, 0.0, False), (0.2, 0, 0.0, True)]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {0: [(0.8, 0, 0.0, True), (0.0, 0, 0.0, True), (0.2, 0, 0.0, True)],\n",
              "  1: [(0.8, 0, 0.0, True), (0.0, 0, 0.0, True), (0.2, 0, 0.0, True)]},\n",
              " 1: {0: [(0.8, 0, 0.0, True), (0.0, 1, 0.0, False), (0.2, 2, 1.0, True)],\n",
              "  1: [(0.8, 2, 1.0, True), (0.0, 1, 0.0, False), (0.2, 0, 0.0, True)]},\n",
              " 2: {0: [(0.8, 2, 0.0, True), (0.0, 2, 0.0, True), (0.2, 2, 0.0, True)],\n",
              "  1: [(0.8, 2, 0.0, True), (0.0, 2, 0.0, True), (0.2, 2, 0.0, True)]}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P = gym.make('BanditWalk-v0').env.P\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlwp6NWa63-n",
        "outputId": "b9328f22-260c-470d-dfcb-fec596d48b91"
      },
      "id": "Vlwp6NWa63-n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {0: [(1.0, 0, 0.0, True), (0.0, 0, 0.0, True), (0.0, 0, 0.0, True)],\n",
              "  1: [(1.0, 0, 0.0, True), (0.0, 0, 0.0, True), (0.0, 0, 0.0, True)]},\n",
              " 1: {0: [(1.0, 0, 0.0, True), (0.0, 1, 0.0, False), (0.0, 2, 1.0, True)],\n",
              "  1: [(1.0, 2, 1.0, True), (0.0, 1, 0.0, False), (0.0, 0, 0.0, True)]},\n",
              " 2: {0: [(1.0, 2, 0.0, True), (0.0, 2, 0.0, True), (0.0, 2, 0.0, True)],\n",
              "  1: [(1.0, 2, 0.0, True), (0.0, 2, 0.0, True), (0.0, 2, 0.0, True)]}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P = gym.make('FrozenLake-v1').env.P\n",
        "len(P),P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqbria-B7LMD",
        "outputId": "cd2e7433-e600-4270-ed1c-1174898655c1"
      },
      "id": "Zqbria-B7LMD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16,\n",
              " {0: {0: [(0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False),\n",
              "    (0.3333333333333333, 1, 0.0, False)],\n",
              "   2: [(0.3333333333333333, 4, 0.0, False),\n",
              "    (0.3333333333333333, 1, 0.0, False),\n",
              "    (0.3333333333333333, 0, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 1, 0.0, False),\n",
              "    (0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 0, 0.0, False)]},\n",
              "  1: {0: [(0.3333333333333333, 1, 0.0, False),\n",
              "    (0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True)],\n",
              "   1: [(0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 2, 0.0, False)],\n",
              "   2: [(0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 1, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 1, 0.0, False),\n",
              "    (0.3333333333333333, 0, 0.0, False)]},\n",
              "  2: {0: [(0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 1, 0.0, False),\n",
              "    (0.3333333333333333, 6, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 1, 0.0, False),\n",
              "    (0.3333333333333333, 6, 0.0, False),\n",
              "    (0.3333333333333333, 3, 0.0, False)],\n",
              "   2: [(0.3333333333333333, 6, 0.0, False),\n",
              "    (0.3333333333333333, 3, 0.0, False),\n",
              "    (0.3333333333333333, 2, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 3, 0.0, False),\n",
              "    (0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 1, 0.0, False)]},\n",
              "  3: {0: [(0.3333333333333333, 3, 0.0, False),\n",
              "    (0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 7, 0.0, True)],\n",
              "   1: [(0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 7, 0.0, True),\n",
              "    (0.3333333333333333, 3, 0.0, False)],\n",
              "   2: [(0.3333333333333333, 7, 0.0, True),\n",
              "    (0.3333333333333333, 3, 0.0, False),\n",
              "    (0.3333333333333333, 3, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 3, 0.0, False),\n",
              "    (0.3333333333333333, 3, 0.0, False),\n",
              "    (0.3333333333333333, 2, 0.0, False)]},\n",
              "  4: {0: [(0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False),\n",
              "    (0.3333333333333333, 8, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 4, 0.0, False),\n",
              "    (0.3333333333333333, 8, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True)],\n",
              "   2: [(0.3333333333333333, 8, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 0, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 0, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False)]},\n",
              "  5: {0: [(1.0, 5, 0, True)],\n",
              "   1: [(1.0, 5, 0, True)],\n",
              "   2: [(1.0, 5, 0, True)],\n",
              "   3: [(1.0, 5, 0, True)]},\n",
              "  6: {0: [(0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 10, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 10, 0.0, False),\n",
              "    (0.3333333333333333, 7, 0.0, True)],\n",
              "   2: [(0.3333333333333333, 10, 0.0, False),\n",
              "    (0.3333333333333333, 7, 0.0, True),\n",
              "    (0.3333333333333333, 2, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 7, 0.0, True),\n",
              "    (0.3333333333333333, 2, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True)]},\n",
              "  7: {0: [(1.0, 7, 0, True)],\n",
              "   1: [(1.0, 7, 0, True)],\n",
              "   2: [(1.0, 7, 0, True)],\n",
              "   3: [(1.0, 7, 0, True)]},\n",
              "  8: {0: [(0.3333333333333333, 4, 0.0, False),\n",
              "    (0.3333333333333333, 8, 0.0, False),\n",
              "    (0.3333333333333333, 12, 0.0, True)],\n",
              "   1: [(0.3333333333333333, 8, 0.0, False),\n",
              "    (0.3333333333333333, 12, 0.0, True),\n",
              "    (0.3333333333333333, 9, 0.0, False)],\n",
              "   2: [(0.3333333333333333, 12, 0.0, True),\n",
              "    (0.3333333333333333, 9, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 9, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False),\n",
              "    (0.3333333333333333, 8, 0.0, False)]},\n",
              "  9: {0: [(0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 8, 0.0, False),\n",
              "    (0.3333333333333333, 13, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 8, 0.0, False),\n",
              "    (0.3333333333333333, 13, 0.0, False),\n",
              "    (0.3333333333333333, 10, 0.0, False)],\n",
              "   2: [(0.3333333333333333, 13, 0.0, False),\n",
              "    (0.3333333333333333, 10, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True)],\n",
              "   3: [(0.3333333333333333, 10, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, True),\n",
              "    (0.3333333333333333, 8, 0.0, False)]},\n",
              "  10: {0: [(0.3333333333333333, 6, 0.0, False),\n",
              "    (0.3333333333333333, 9, 0.0, False),\n",
              "    (0.3333333333333333, 14, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 9, 0.0, False),\n",
              "    (0.3333333333333333, 14, 0.0, False),\n",
              "    (0.3333333333333333, 11, 0.0, True)],\n",
              "   2: [(0.3333333333333333, 14, 0.0, False),\n",
              "    (0.3333333333333333, 11, 0.0, True),\n",
              "    (0.3333333333333333, 6, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 11, 0.0, True),\n",
              "    (0.3333333333333333, 6, 0.0, False),\n",
              "    (0.3333333333333333, 9, 0.0, False)]},\n",
              "  11: {0: [(1.0, 11, 0, True)],\n",
              "   1: [(1.0, 11, 0, True)],\n",
              "   2: [(1.0, 11, 0, True)],\n",
              "   3: [(1.0, 11, 0, True)]},\n",
              "  12: {0: [(1.0, 12, 0, True)],\n",
              "   1: [(1.0, 12, 0, True)],\n",
              "   2: [(1.0, 12, 0, True)],\n",
              "   3: [(1.0, 12, 0, True)]},\n",
              "  13: {0: [(0.3333333333333333, 9, 0.0, False),\n",
              "    (0.3333333333333333, 12, 0.0, True),\n",
              "    (0.3333333333333333, 13, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 12, 0.0, True),\n",
              "    (0.3333333333333333, 13, 0.0, False),\n",
              "    (0.3333333333333333, 14, 0.0, False)],\n",
              "   2: [(0.3333333333333333, 13, 0.0, False),\n",
              "    (0.3333333333333333, 14, 0.0, False),\n",
              "    (0.3333333333333333, 9, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 14, 0.0, False),\n",
              "    (0.3333333333333333, 9, 0.0, False),\n",
              "    (0.3333333333333333, 12, 0.0, True)]},\n",
              "  14: {0: [(0.3333333333333333, 10, 0.0, False),\n",
              "    (0.3333333333333333, 13, 0.0, False),\n",
              "    (0.3333333333333333, 14, 0.0, False)],\n",
              "   1: [(0.3333333333333333, 13, 0.0, False),\n",
              "    (0.3333333333333333, 14, 0.0, False),\n",
              "    (0.3333333333333333, 15, 1.0, True)],\n",
              "   2: [(0.3333333333333333, 14, 0.0, False),\n",
              "    (0.3333333333333333, 15, 1.0, True),\n",
              "    (0.3333333333333333, 10, 0.0, False)],\n",
              "   3: [(0.3333333333333333, 15, 1.0, True),\n",
              "    (0.3333333333333333, 10, 0.0, False),\n",
              "    (0.3333333333333333, 13, 0.0, False)]},\n",
              "  15: {0: [(1.0, 15, 0, True)],\n",
              "   1: [(1.0, 15, 0, True)],\n",
              "   2: [(1.0, 15, 0, True)],\n",
              "   3: [(1.0, 15, 0, True)]}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Return\n",
        "The Return is the sum of Rewards encountered from step t until the final step T:\n",
        "$$G_t = R_{t+1} + R_{t+2} + R_{t+3} + ...+ R_T$$\n",
        "\n",
        "With discount factor:\n",
        "$$G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2R_{t+3} + ...+ \\gamma^{T-1}R_T$$\n",
        "$$G_t = \\sum_{k=0}^\\infty \\gamma^kR_{t+1+k}$$\n",
        "\n",
        "In recursive form:\n",
        "$$G_t = R_{t+1} + \\gamma G_{t+1}$$"
      ],
      "metadata": {
        "id": "JZDDuPcQ__Qq"
      },
      "id": "JZDDuPcQ__Qq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State-Value Function V\n",
        "AKA Value Function, V-function, $V^\\pi(s)$...\n",
        "\n",
        "Value of state s when following a policy π:\n",
        "$$v_\\pi(s)=\\mathbb{E}_\\pi[G_t|S_t=s]$$\n",
        "Value of a State s under Policy \\pi is the Expectation over \\pi of Returns at time step t given you select State s at time step t.\n",
        "Use recursive form of Return:\n",
        "$$v_\\pi(s)=\\mathbb{E}_\\pi[R_t+\\gamma G_{t+1}|S_t=s]$$\n",
        "\n",
        "**Bellman equation**: it tells us how to find the value of states\n",
        "$$v_\\pi(s)=\\sum_a \\pi(a|s)\\sum_{s', r}\\{p(s',r|s,a)[r+\\gamma v_\\pi(s')]\\}, \\forall s \\in S$$\n",
        "\n",
        "* We get the action (or actions, if policy is stocastic) prescribed for state s. And do a weighted sum...\n",
        "* We also weight the sum over the probability of next states and rewards.\n",
        "* We add the reward and the discounted value of the landing states, weight that by the probabilities.\n",
        "* do this for all states in the state space\n",
        "\n"
      ],
      "metadata": {
        "id": "Dzu6DUvKFXOD"
      },
      "id": "Dzu6DUvKFXOD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action-Value Function Q\n",
        "What to expect from here if I do this?\n",
        "\n",
        "AKA Q-function. or $Q^\\pi(s,a)$: gives us the expected Return if agent follows policy π after taking action a in state s.\n",
        "\n",
        "$$q_\\pi(s, a)=\\mathbb{E}_\\pi[G_t|S_t=s, A_t=a]$$\n",
        "The value of Action a in State s is the expectation of Returns given we select action a in state s and follow policy π thereafter.\n",
        "\n",
        "In recursive form:\n",
        "$$q_\\pi(s,a) =  \\mathbb{E}_\\pi[R_t+\\gamma G_{t+1}|S_t=s, A_t=a]$$\n",
        "\n",
        "The Bellman equation for action-values:\n",
        "$$q_\\pi(s,a)=\\sum_{s',r}\\{p(s',r|s,a)[r+\\gamma v_\\pi(s')]\\}, \\forall s \\in S, \\forall a \\in A(s)$$\n"
      ],
      "metadata": {
        "id": "KTRTzoQ1K34A"
      },
      "id": "KTRTzoQ1K34A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action-Advantage Function\n",
        "i.e. how much better if I do this (comparing to taking the default action under policy π?\n",
        "\n",
        "The advantage of action a in state s under a policy π:\n",
        "$$a_\\pi(s,a)=q_\\pi(s,a)-v_\\pi(s)$$\n"
      ],
      "metadata": {
        "id": "NZ9O6sqWPiFz"
      },
      "id": "NZ9O6sqWPiFz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Learning\n",
        "Downside of Q-learning:\n",
        "* actions space is discrete and small\n",
        "* cannot handle continuous action spaces\n",
        "* policy is deterministically calculated from Q-function by maximising rewards -> cannot learn stochastic policies"
      ],
      "metadata": {
        "id": "MEMn8kMjnarI"
      },
      "id": "MEMn8kMjnarI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Policy Evaluation -> V\n",
        "\n",
        "The policy evaluation equation\n",
        "$$v_{k+1}(s)=\\sum_a \\pi(a|s)\\sum_{s', a}p(s',r|s,a)[r+\\gamma v_k(s')]$$\n",
        "\n",
        "For a deterministic policy (e.g. we always move lefe), $\\sum_a \\pi(a|s)=1$"
      ],
      "metadata": {
        "id": "RbHQBFepvQ_1"
      },
      "id": "RbHQBFepvQ_1"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def policy_evaluation(pi, P, gamma=1.0, theta=1e-10):\n",
        "  prev_V = np.zeros(len(P)) # initialise value for each state to 0\n",
        "  while True:\n",
        "    V = np.zeros(len(P))\n",
        "    for s in range(len(P)):\n",
        "      # example of P[s]pi[s]: [(0.8, 0, 0.0, True), (0.0, 1, 0.0, False), (0.2, 2, 1.0, True)]\n",
        "      for (prob, next_state, reward, done) in P[s][pi[s]]:\n",
        "        # multiply by not done s.t. V(s)=0 if s is terminal state\n",
        "        V[s] += prob * (reward + gamma * prev_V[next_state] * (not done) )\n",
        "    # stop the while loop if values have converged\n",
        "    if np.max(np.abs(prev_V - V)) < theta:\n",
        "      break\n",
        "\n",
        "    prev_V = V.copy()\n",
        "  return V"
      ],
      "metadata": {
        "id": "fMVvKZDq_-hL"
      },
      "id": "fMVvKZDq_-hL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate SWF\n",
        "Apply the above on Slippery Walk Five environment, using a policy of 'always left'.\n",
        "```\n",
        " _________________________________\n",
        "| H 0 | 1 | 2 | S 3 | 4 | 5 | G 6 |\n",
        " ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "```\n",
        "There are 7 states in this env, H=hole, G=Goal, S=Start"
      ],
      "metadata": {
        "id": "iuzh7Y9lnCZc"
      },
      "id": "iuzh7Y9lnCZc"
    },
    {
      "cell_type": "code",
      "source": [
        "P = gym.make('SlipperyWalkFive-v0').env.P\n",
        "len(P),P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTfYx4PUyXbx",
        "outputId": "d7c86692-297a-41f8-e3c6-136cded64d9d"
      },
      "id": "uTfYx4PUyXbx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7,\n",
              " {0: {0: [(0.5000000000000001, 0, 0.0, True),\n",
              "    (0.3333333333333333, 0, 0.0, True),\n",
              "    (0.16666666666666666, 0, 0.0, True)],\n",
              "   1: [(0.5000000000000001, 0, 0.0, True),\n",
              "    (0.3333333333333333, 0, 0.0, True),\n",
              "    (0.16666666666666666, 0, 0.0, True)]},\n",
              "  1: {0: [(0.5000000000000001, 0, 0.0, True),\n",
              "    (0.3333333333333333, 1, 0.0, False),\n",
              "    (0.16666666666666666, 2, 0.0, False)],\n",
              "   1: [(0.5000000000000001, 2, 0.0, False),\n",
              "    (0.3333333333333333, 1, 0.0, False),\n",
              "    (0.16666666666666666, 0, 0.0, True)]},\n",
              "  2: {0: [(0.5000000000000001, 1, 0.0, False),\n",
              "    (0.3333333333333333, 2, 0.0, False),\n",
              "    (0.16666666666666666, 3, 0.0, False)],\n",
              "   1: [(0.5000000000000001, 3, 0.0, False),\n",
              "    (0.3333333333333333, 2, 0.0, False),\n",
              "    (0.16666666666666666, 1, 0.0, False)]},\n",
              "  3: {0: [(0.5000000000000001, 2, 0.0, False),\n",
              "    (0.3333333333333333, 3, 0.0, False),\n",
              "    (0.16666666666666666, 4, 0.0, False)],\n",
              "   1: [(0.5000000000000001, 4, 0.0, False),\n",
              "    (0.3333333333333333, 3, 0.0, False),\n",
              "    (0.16666666666666666, 2, 0.0, False)]},\n",
              "  4: {0: [(0.5000000000000001, 3, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False),\n",
              "    (0.16666666666666666, 5, 0.0, False)],\n",
              "   1: [(0.5000000000000001, 5, 0.0, False),\n",
              "    (0.3333333333333333, 4, 0.0, False),\n",
              "    (0.16666666666666666, 3, 0.0, False)]},\n",
              "  5: {0: [(0.5000000000000001, 4, 0.0, False),\n",
              "    (0.3333333333333333, 5, 0.0, False),\n",
              "    (0.16666666666666666, 6, 1.0, True)],\n",
              "   1: [(0.5000000000000001, 6, 1.0, True),\n",
              "    (0.3333333333333333, 5, 0.0, False),\n",
              "    (0.16666666666666666, 4, 0.0, False)]},\n",
              "  6: {0: [(0.5000000000000001, 6, 0.0, True),\n",
              "    (0.3333333333333333, 6, 0.0, True),\n",
              "    (0.16666666666666666, 6, 0.0, True)],\n",
              "   1: [(0.5000000000000001, 6, 0.0, True),\n",
              "    (0.3333333333333333, 6, 0.0, True),\n",
              "    (0.16666666666666666, 6, 0.0, True)]}})"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the always-left policy\n",
        "LEFT=0\n",
        "RIGHT=1\n",
        "n_states=len(P)\n",
        "pi_always_left={}\n",
        "for state in range(n_states): # ignore states 0 and 6 since they are terminal\n",
        "  pi_always_left[state] = LEFT"
      ],
      "metadata": {
        "id": "kui1Nl9NnTnW"
      },
      "id": "kui1Nl9NnTnW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi_always_left"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ta0tontQvz-",
        "outputId": "b23e8a9b-4f77-46f6-cd50-834641822576"
      },
      "id": "4ta0tontQvz-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V_pi_always_left = policy_evaluation(pi_always_left, P)"
      ],
      "metadata": {
        "id": "eDfC_4roRYm2"
      },
      "id": "eDfC_4roRYm2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V_pi_always_left"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZmVwtSGTAQt",
        "outputId": "da49e479-4bda-427a-eb24-00466a68c133"
      },
      "id": "kZmVwtSGTAQt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.00274725, 0.01098901, 0.03571429, 0.10989011,\n",
              "       0.33241758, 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate FL\n",
        "Frozen Lake: 16 states, 4 actions (L, D, R, U)\n",
        "We will evaluate 3 policies: random, eager, careful\n"
      ],
      "metadata": {
        "id": "k4cQcw5uV_De"
      },
      "id": "k4cQcw5uV_De"
    },
    {
      "cell_type": "code",
      "source": [
        "P = gym.make('FrozenLake-v1').env.P;\n",
        "n_states = len(P)\n",
        "# actions\n",
        "LEFT, DOWN, RIGHT, UP = 0, 1, 2, 3\n",
        "decode_action = lambda i: ['L', 'D', 'R', 'U'][i]\n",
        "# I will use UP for holes since it's easier to type\n",
        "pi_random={\n",
        "    0:RIGHT, 1:LEFT, 2:DOWN, 3:UP,\n",
        "    4:LEFT, 5:UP, 6:RIGHT, 7:UP,\n",
        "    8:UP, 9:DOWN, 10:UP, 11:UP,\n",
        "    12:UP, 13:RIGHT, 14:DOWN, 15:UP\n",
        "    }"
      ],
      "metadata": {
        "id": "CJP97EM8XICu"
      },
      "id": "CJP97EM8XICu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V_random=policy_evaluation(pi_random, P, 0.99) ;\n",
        "print(\"Random Policy value at START: %.4f\" % V_random[0]);\n",
        "V_random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCNcwjRcYdgs",
        "outputId": "9cdc0dea-4529-47ad-e6b1-8f91cfdcf251"
      },
      "id": "TCNcwjRcYdgs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Policy value at START: 0.0955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09554433, 0.04705915, 0.0470064 , 0.04562386, 0.1469248 ,\n",
              "       0.        , 0.04976062, 0.        , 0.20275753, 0.26473443,\n",
              "       0.10378337, 0.        , 0.        , 0.49568466, 0.74165563,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "pi_true_random = {s:random.randint(0, 3) for s in range(n_states)}\n",
        "print(\"random policy: \", pi_true_random)\n",
        "V_true_random = policy_evaluation(pi_true_random, P, 0.99)\n",
        "print(\"True random Policy value at START: %.4f\" % V_true_random[0])\n",
        "V_true_random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ74fC69b78F",
        "outputId": "60762aa2-0ebb-4a2d-a758-b66d33b04e02"
      },
      "id": "rZ74fC69b78F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random policy:  {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0, 6: 3, 7: 0, 8: 0, 9: 3, 10: 3, 11: 1, 12: 2, 13: 0, 14: 0, 15: 2}\n",
            "True random Policy value at START: 0.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_eager = {\n",
        "    0:RIGHT, 1:RIGHT, 2:DOWN, 3: LEFT,\n",
        "    4:DOWN, 5:UP, 6: DOWN, 7:UP,\n",
        "    8:RIGHT, 9:RIGHT, 10:DOWN, 11:UP,\n",
        "    12:UP, 13:RIGHT, 14:RIGHT, 15:UP\n",
        "}\n",
        "V_eager=policy_evaluation(pi_eager, P, 0.99) ;\n",
        "print(\"Eager Policy value at START: %.4f\" % V_eager[0]);\n",
        "V_eager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yowa-hhmYpnJ",
        "outputId": "e3ed4b8c-2da7-4b25-bfe1-aad3017dfe8c"
      },
      "id": "Yowa-hhmYpnJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eager Policy value at START: 0.0342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03416037, 0.02305118, 0.04680089, 0.02305118, 0.04630471,\n",
              "       0.        , 0.09571851, 0.        , 0.0940126 , 0.23858195,\n",
              "       0.29005609, 0.        , 0.        , 0.43291953, 0.64037588,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_careful = {\n",
        "    0:LEFT, 1:UP, 2:UP, 3: UP,\n",
        "    4:LEFT, 5:UP, 6: UP, 7:UP,\n",
        "    8:UP, 9:DOWN, 10:LEFT, 11:UP,\n",
        "    12:UP, 13:RIGHT, 14:RIGHT, 15:UP\n",
        "}\n",
        "V_careful=policy_evaluation(pi_careful, P, 0.99) ;\n",
        "print(\"Careful Policy value at START: %.4f\" % V_careful[0]);\n",
        "V_careful"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfBJnVXQbNyw",
        "outputId": "7dfa115f-a59b-4c0e-dce8-669f9bf4ad43"
      },
      "id": "UfBJnVXQbNyw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Careful Policy value at START: 0.4079\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4079433 , 0.3754127 , 0.35425824, 0.34383888, 0.42030522,\n",
              "       0.        , 0.11690522, 0.        , 0.44540366, 0.48399918,\n",
              "       0.43282831, 0.        , 0.        , 0.58843221, 0.71069653,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Policy Improvement -> π\n",
        "To improve a policy, we use a state-value function and an MDP to get a one-step lookahead and determine which of the actions lead to the highest value. This is policy improvement equation:\n",
        "$$\\pi'(s)=arg\\max_{a}\\sum_{s',r}p(s',r|s,a)[r+\\gamma v_\\pi(s')]$$\n",
        "\n",
        "We obtain a new policy π' by taking the highest-valued action. How do we get the highest-valued action: by calculating for each action, the weighted sum of all rewards and values of all possible next states.\n",
        "\n",
        "Notice that this is simply using the action with the highest-valued Q-function.\n",
        "\n",
        "Downside of Q-learning:\n",
        "\n",
        "* actions space is discrete and small\n",
        "* cannot handle continuous action spaces\n",
        "* policy is deterministically calculated from Q-function by maximising rewards -> cannot learn stochastic policies\n",
        "\n"
      ],
      "metadata": {
        "id": "1gK9stMgbnDd"
      },
      "id": "1gK9stMgbnDd"
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax([1,2,2,1]), np.argmax([1,2,1,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9AsXff08201",
        "outputId": "d26e651d-2ec1-437d-e92c-9af2d37235c9"
      },
      "id": "y9AsXff08201",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_improvement(V, P, gamma=1.0):\n",
        "  n_states = len(P)\n",
        "  n_actions = len(P[0])\n",
        "  # initialise Q-function to zeros\n",
        "  Q = np.zeros((n_states, n_actions), dtype=np.float64)\n",
        "  for s in range(n_states):\n",
        "    for a in range(n_actions):\n",
        "      for prob, next_state, reward, done in P[s][a]:\n",
        "        Q[s,a] += prob * (reward + gamma * V[next_state] * (not done))\n",
        "  print(\"Q-function: \\n\", Q)\n",
        "  new_pi = {s:a for s, a in enumerate( np.argmax(Q, axis=1) )}\n",
        "  #new_pi = lambda s: {s:a for s, a in enumerate( np.argmax(Q, axis=1) )}[s]\n",
        "\n",
        "  return new_pi"
      ],
      "metadata": {
        "id": "sbOj6e8Gbqhu"
      },
      "id": "sbOj6e8Gbqhu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pi_careful = policy_improvement(V_careful, P, gamma=0.99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i9rvyufkLrr",
        "outputId": "d45c2395-df40-42dc-8a37-e4d8cb3cc98c"
      },
      "id": "1i9rvyufkLrr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-function: \n",
            " [[0.4079433  0.3972082  0.3972082  0.39312877]\n",
            " [0.25850748 0.25152651 0.24079141 0.3754127 ]\n",
            " [0.27937013 0.27593174 0.26895077 0.35425824]\n",
            " [0.23037205 0.23037205 0.22693366 0.34383888]\n",
            " [0.42030522 0.28568393 0.2816045  0.27332201]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.25973856 0.14283334 0.25973856 0.11690522]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.28568393 0.30670294 0.29842045 0.44540366]\n",
            " [0.34116584 0.48399918 0.33701597 0.28981655]\n",
            " [0.43282831 0.39424958 0.27310858 0.19829845]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.35390236 0.42871248 0.58843221 0.39424958]\n",
            " [0.57154583 0.76204582 0.71069653 0.6703493 ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_pi_careful)\n",
        "print({s:decode_action(new_pi_careful[s]) for s in range(n_states)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMsbLxg0oeGg",
        "outputId": "74816266-3026-4d02-bb68-2f674735a8c2"
      },
      "id": "dMsbLxg0oeGg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0, 1: 3, 2: 3, 3: 3, 4: 0, 5: 0, 6: 0, 7: 0, 8: 3, 9: 1, 10: 0, 11: 0, 12: 0, 13: 2, 14: 1, 15: 0}\n",
            "{0: 'L', 1: 'U', 2: 'U', 3: 'U', 4: 'L', 5: 'L', 6: 'L', 7: 'L', 8: 'U', 9: 'D', 10: 'L', 11: 'L', 12: 'L', 13: 'R', 14: 'D', 15: 'L'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d1={'a': 1, 'b': 2, 'c': 3}\n",
        "d2=d1.copy()\n",
        "#d2['c']=4\n",
        "d2==d1, d1==d2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYvLKUk9qMgT",
        "outputId": "915c9414-8285-455c-e5c6-7bc0cf4e47f5"
      },
      "id": "sYvLKUk9qMgT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Policy Iteration -> V, π*\n",
        "Policy iteration is guaranteed to converge to optimal policy. We need to make sure if there is a tie in action-value function, we need to have a way to deterministically choose an action (not randomly). The np.argmax() (used in policy_improvement) works deterministically - it uses the index of the first found element."
      ],
      "metadata": {
        "id": "F4ewcEyMwvxP"
      },
      "id": "F4ewcEyMwvxP"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def policy_iteration(V, P, gamma=1.0, theta=1e-10):\n",
        "  n_states = len(P)\n",
        "  n_actions = len(P[0])\n",
        "  # initialise policy to random actions.\n",
        "  pi = {s:random.randint(0, n_actions-1) for s in range(n_states)}\n",
        "\n",
        "  while True:\n",
        "    old_pi = pi.copy() # no nested dict, no shallow copy only\n",
        "    print(\"current Pi: \", [decode_action(a) for s, a in pi.items()])\n",
        "    V = policy_evaluation(pi, P, gamma, theta)\n",
        "    print(\"current V: \", V)\n",
        "    pi = policy_improvement(V, P, gamma)\n",
        "    if old_pi == pi:\n",
        "      break # stop improving if converged\n",
        "\n",
        "  return V, pi"
      ],
      "metadata": {
        "id": "oZtZdQ9txMZu"
      },
      "id": "oZtZdQ9txMZu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try it with a random V\n",
        "V, pi = policy_iteration(V_true_random, P, 0.99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u2RUP4Vz6B6",
        "outputId": "014ac941-52ce-4042-a5b7-ac16e79d52a5"
      },
      "id": "_u2RUP4Vz6B6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current Pi:  ['R', 'L', 'U', 'L', 'L', 'U', 'L', 'R', 'R', 'R', 'D', 'U', 'R', 'U', 'U', 'D']\n",
            "current V:  [0.02628938 0.0129485  0.00842033 0.00414733 0.04042691 0.\n",
            " 0.0670948  0.         0.0557895  0.12863218 0.19489724 0.\n",
            " 0.         0.19489724 0.46196551 0.        ]\n",
            "Q-function: \n",
            " [[0.03069187 0.02628938 0.02628938 0.021624  ]\n",
            " [0.0129485  0.01145421 0.00705172 0.01572721]\n",
            " [0.029193   0.02778291 0.02628861 0.00842033]\n",
            " [0.00414733 0.00414733 0.00273724 0.00551595]\n",
            " [0.04042691 0.03175142 0.02708603 0.02201638]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.0670948  0.06431609 0.0670948  0.00277871]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.03175142 0.06085915 0.0557895  0.07420003]\n",
            " [0.08272662 0.14704271 0.12863218 0.08272662]\n",
            " [0.21703852 0.19489724 0.1745899  0.0645899 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.10676471 0.21676471 0.25921332 0.19489724]\n",
            " [0.28108079 0.55009804 0.55009804 0.46196551]\n",
            " [0.         0.         0.         0.        ]]\n",
            "current Pi:  ['L', 'U', 'L', 'U', 'L', 'L', 'L', 'L', 'U', 'D', 'L', 'L', 'L', 'R', 'D', 'L']\n",
            "current V:  [0.53248009 0.4497886  0.38072706 0.36952921 0.54861585 0.\n",
            " 0.32320271 0.         0.58137634 0.63175429 0.59867508 0.\n",
            " 0.         0.73435551 0.85920993 0.        ]\n",
            "Q-function: \n",
            " [[0.53248009 0.5051919  0.5051919  0.4998671 ]\n",
            " [0.32414867 0.30135836 0.27407017 0.4497886 ]\n",
            " [0.38072706 0.37703177 0.35424146 0.39601481]\n",
            " [0.24758457 0.24758457 0.24388928 0.36952921]\n",
            " [0.54861585 0.37289742 0.36757262 0.35676166]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.32320271 0.19756278 0.32320271 0.12563993]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.37289742 0.40033311 0.38952215 0.58137634]\n",
            " [0.43419151 0.63175429 0.4399001  0.38941697]\n",
            " [0.59867508 0.49201819 0.39019617 0.31513581]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.45081623 0.52587659 0.73435551 0.49201819]\n",
            " [0.72343937 0.85920993 0.81443539 0.77323343]\n",
            " [0.         0.         0.         0.        ]]\n",
            "current Pi:  ['L', 'U', 'U', 'U', 'L', 'L', 'L', 'L', 'U', 'D', 'L', 'L', 'L', 'R', 'D', 'L']\n",
            "current V:  [0.54202593 0.49880319 0.47069569 0.4568517  0.55845096 0.\n",
            " 0.35834807 0.         0.59179874 0.64307982 0.61520756 0.\n",
            " 0.         0.74172044 0.86283743 0.        ]\n",
            "Q-function: \n",
            " [[0.54202593 0.52776242 0.52776242 0.52234217]\n",
            " [0.34347361 0.33419813 0.31993463 0.49880319]\n",
            " [0.43818949 0.43362097 0.4243455  0.47069569]\n",
            " [0.30609064 0.30609064 0.30152212 0.4568517 ]\n",
            " [0.55845096 0.3795824  0.37416214 0.36315737]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.35834807 0.20301849 0.35834807 0.15532958]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.3795824  0.40750993 0.39650516 0.59179874]\n",
            " [0.44006133 0.64307982 0.44778624 0.39831208]\n",
            " [0.61520756 0.49695269 0.40299122 0.33047121]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.45698409 0.5295041  0.74172044 0.49695269]\n",
            " [0.73252259 0.86283743 0.82108818 0.78111957]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(V)\n",
        "print([decode_action(a) for s, a in pi.items()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F4r0sOX0nci",
        "outputId": "0d3725d1-b5b8-4ce0-c6b0-f5bed8f988fd"
      },
      "id": "0F4r0sOX0nci",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.54202593 0.49880319 0.47069569 0.4568517  0.55845096 0.\n",
            " 0.35834807 0.         0.59179874 0.64307982 0.61520756 0.\n",
            " 0.         0.74172044 0.86283743 0.        ]\n",
            "['L', 'U', 'U', 'U', 'L', 'L', 'L', 'L', 'U', 'D', 'L', 'L', 'L', 'R', 'D', 'L']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Value Iteration (VI) -> V, π*\n",
        "Improving behaviours early: only do one-step for policy evaluation, then do policy improvement.\n",
        "\n",
        "We can merge the truncated policy evaluation step and a policy improvement into the same equation:\n",
        "$$v_{k+1}(s) = \\max_a \\sum_{s', r}p(s',r|s,a)[r+\\gamma v_k(s')]$$\n",
        "\n",
        "Note that we don't deal with policies at all. It does it through value functions only, hence VI."
      ],
      "metadata": {
        "id": "rsmPVMwm9TyX"
      },
      "id": "rsmPVMwm9TyX"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def value_iteration(P, gamma=1.0, theta=1e-10):\n",
        "  n_states = len(P)\n",
        "  n_actions = len(P[0])\n",
        "  # initialise V to zeros\n",
        "  V = np.zeros(n_states, dtype=np.float64)\n",
        "\n",
        "  while True:\n",
        "    # initialise Q-function to zeros\n",
        "    Q = np.zeros((n_states, n_actions), dtype=np.float64)\n",
        "    for s in range(n_states):\n",
        "      for a in range(n_actions):\n",
        "        for prob, next_state, reward, done in P[s][a]:\n",
        "          Q[s,a] += prob * (reward + gamma * V[next_state] * (not done))\n",
        "    if np.max( np.abs(V - np.max(Q, axis=1)) ) < theta:\n",
        "      break; # if the action-advantage function converged, break\n",
        "\n",
        "    V = np.max(Q, axis=1) # combination of policy eval and improv\n",
        "  pi = {s:a for s, a in enumerate( np.argmax(Q, axis=1) )}\n",
        "\n",
        "  return V, pi\n"
      ],
      "metadata": {
        "id": "pxBuDHKM96a8"
      },
      "id": "pxBuDHKM96a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V2,pi2=value_iteration(P, 0.99)\n",
        "print(V2)\n",
        "print([decode_action(a) for s, a in pi2.items()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuENFpPVEUPU",
        "outputId": "4bee3f9f-9104-4a2e-b3d0-9d6bd9e9233a"
      },
      "id": "IuENFpPVEUPU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.54202593 0.49880318 0.47069569 0.4568517  0.55845096 0.\n",
            " 0.35834807 0.         0.59179874 0.64307982 0.61520756 0.\n",
            " 0.         0.74172044 0.86283743 0.        ]\n",
            "['L', 'U', 'U', 'U', 'L', 'L', 'L', 'L', 'U', 'D', 'L', 'L', 'L', 'R', 'D', 'L']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(V)\n",
        "print([decode_action(a) for s, a in pi.items()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh4ecdafFk1C",
        "outputId": "26c40992-c917-45b1-d330-093e278e5626"
      },
      "id": "Vh4ecdafFk1C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.54202593 0.49880319 0.47069569 0.4568517  0.55845096 0.\n",
            " 0.35834807 0.         0.59179874 0.64307982 0.61520756 0.\n",
            " 0.         0.74172044 0.86283743 0.        ]\n",
            "['L', 'U', 'U', 'U', 'L', 'L', 'L', 'L', 'U', 'D', 'L', 'L', 'L', 'R', 'D', 'L']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "pi==pi2, all(math.isclose(v1, v2, abs_tol=1e-10) for v1, v2 in zip(V, V2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCCPIlW7Fqma",
        "outputId": "e25772db-570f-424a-dbec-51cf67611395"
      },
      "id": "MCCPIlW7Fqma",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Armed Bandit (MAB)\n",
        "\n",
        "MABs are MDPs with\n",
        "* single non-terminal state, and\n",
        "* single timestep per episode (horizon=1)\n",
        "\n",
        "$$MAB = MDP(\\mathcal S=\\{s\\}, \\mathcal A, \\mathcal T, \\mathcal R, \\mathcal S_\\theta=\\{s\\}, \\gamma=1, \\mathcal H=1)$$\n",
        "\n",
        "Q-function of action a|s of MAB:\n",
        "$$q(a) = \\mathbb E [R_t|A_t=a]$$\n",
        "\n",
        "The best we can do in a MAB is represented by the optimal V-function, or selecting the action that maximises the Q-function:\n",
        "$$v^*=q(a_*)=\\max_{a \\in A}q(a)$$\n",
        "\n",
        "The optimal action is the action that maximises the optimal Q-function and optimal V-function (only 1 state)\n",
        "$$a_*=arg\\max_{a \\in A}q(a)$$"
      ],
      "metadata": {
        "id": "AAhQ3ZOqh_DD"
      },
      "id": "AAhQ3ZOqh_DD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Total Regret\n",
        "\n",
        "The Total Regret equation:\n",
        "$$\\mathcal T = \\sum_{e=1}^E \\mathbb E[v_*-q_*(A_e)]$$\n",
        "To calculate the total regret: add up for all the episodes: the difference between the optimal value of the MAB and the *true value of the action selected*."
      ],
      "metadata": {
        "id": "WHt0dtDVrLgR"
      },
      "id": "WHt0dtDVrLgR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Class for Strategies\n",
        "\n",
        "Here is a base class to be inherited by actual strategies."
      ],
      "metadata": {
        "id": "mvnvwGTcN0fe"
      },
      "id": "mvnvwGTcN0fe"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "# base class for all the strategies below.\n",
        "class StrategyBase:\n",
        "  def __init__(self, name, env, n_episodes=5000):\n",
        "    assert isinstance(n_episodes, int), \"n_episodes must be integer\"\n",
        "    assert n_episodes>0, \"n_episodes must be greater than 0\"\n",
        "    self.name = name\n",
        "    self.env = env\n",
        "    self.n_episodes = n_episodes\n",
        "\n",
        "    self.Q = np.zeros((env.action_space.n))\n",
        "    self.N = np.zeros((env.action_space.n))\n",
        "\n",
        "    # for monitoring and stats only, not necessary for the algorithm\n",
        "    self.Qe = np.empty((n_episodes, env.action_space.n))\n",
        "    self.returns = np.empty(n_episodes)\n",
        "    self.actions = np.empty(n_episodes)\n",
        "\n",
        "  def update(self, e, action):\n",
        "    _, reward, _, _ = self.env.step(action)\n",
        "    self.N[action] += 1\n",
        "    self.Q[action] = self.Q[action] + (reward - self.Q[action]) / self.N[action]\n",
        "\n",
        "    self.Qe[e] = self.Q\n",
        "    self.returns[e] = reward\n",
        "    self.actions[e] = action\n",
        "\n",
        "  # to be implemented by child classes\n",
        "  def run(self):\n",
        "    pass\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.name"
      ],
      "metadata": {
        "id": "zgnchXz6Ny10"
      },
      "id": "zgnchXz6Ny10",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pure Exploitation Strategy\n",
        "This baseline is called *greedy strategy*, or *pure exploitation strategy*. The greedy actionselection\n",
        "approach consists of always selecting the action with the highest estimated value.\n",
        "While there is a chance for the very first action, we choose to be the best overall action, the likelihood of this lucky coincidence decreases as the number of available actions increases."
      ],
      "metadata": {
        "id": "HE3gaexjzSVv"
      },
      "id": "HE3gaexjzSVv"
    },
    {
      "cell_type": "code",
      "source": [
        "def pure_exploitation(env, n_episodes=5000):\n",
        "  Q = np.zeros((env.action_space.n))\n",
        "  N = np.zeros((env.action_space.n))\n",
        "\n",
        "  # for monitoring and stats only, not necessary for the algorithm\n",
        "  Qe = np.empty((n_episodes, env.action_space.n))\n",
        "  returns = np.empty(n_episodes)\n",
        "  actions = np.empty(n_episodes)\n",
        "\n",
        "  name = 'Pure Exploitation'\n",
        "  for e in tqdm(range(n_episodes), desc=f\"Episodes for {name}\", leave=False):\n",
        "    action = np.argmax(Q)\n",
        "    _, reward, _, _ = env.step(action)\n",
        "    N[action] += 1\n",
        "    Q[action] = Q[action] + (reward - Q[action]) / N[action]\n",
        "\n",
        "    Qe[e] = Q\n",
        "    returns[e] = reward\n",
        "    actions[e] = action\n",
        "\n",
        "  return name, returns, Qe, actions"
      ],
      "metadata": {
        "id": "GE79-_F-iFCM"
      },
      "id": "GE79-_F-iFCM",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pure Exploration Strategy\n",
        "This is another fundamental baseline which we can call a *random strategy* or a *pure exploration strategy*. This is simply an approach to action selection with no exploitation at all. The sole goal of the agent is to gain information."
      ],
      "metadata": {
        "id": "95Yq8BIU5jTx"
      },
      "id": "95Yq8BIU5jTx"
    },
    {
      "cell_type": "code",
      "source": [
        "def pure_exploration(env, n_episodes=5000):\n",
        "  Q = np.zeros((env.action_space.n))\n",
        "  N = np.zeros((env.action_space.n))\n",
        "\n",
        "  # for monitoring and stats only, not necessary for the algorithm\n",
        "  Qe = np.empty((n_episodes, env.action_space.n))\n",
        "  returns = np.empty(n_episodes)\n",
        "  actions = np.empty(n_episodes)\n",
        "\n",
        "  name = 'Pure Exploration'\n",
        "  for e in tqdm(range(n_episodes), desc=f\"Episodes for {name}\", leave=False):\n",
        "    action = np.random.randint(len(Q))\n",
        "    _, reward, _, _ = env.step(action)\n",
        "    N[action] += 1\n",
        "    Q[action] = Q[action] + (reward - Q[action]) / N[action]\n",
        "\n",
        "    Qe[e] = Q\n",
        "    returns[e] = reward\n",
        "    actions[e] = action\n",
        "\n",
        "  return name, returns, Qe, actions"
      ],
      "metadata": {
        "id": "_wqNfXaK126f"
      },
      "id": "_wqNfXaK126f",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ϵ-Greedy\n",
        "\n",
        "Almost always greedy, just sometimes random."
      ],
      "metadata": {
        "id": "0aJ7QHUV8EHE"
      },
      "id": "0aJ7QHUV8EHE"
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_greedy(env, epsilon=0.01, n_episodes=5000):\n",
        "  Q = np.zeros((env.action_space.n))\n",
        "  N = np.zeros((env.action_space.n))\n",
        "\n",
        "  # for monitoring and stats only, not necessary for the algorithm\n",
        "  Qe = np.empty((n_episodes, env.action_space.n))\n",
        "  returns = np.empty(n_episodes)\n",
        "  actions = np.empty(n_episodes)\n",
        "\n",
        "  name = f'Epsilon-Greedy {epsilon}'\n",
        "  for e in tqdm(range(n_episodes), desc=f\"Episodes for {name}\", leave=False):\n",
        "    if np.random.random() > epsilon:\n",
        "      action = np.argmax(Q)\n",
        "    else:\n",
        "      action = np.random.randint(len(Q))\n",
        "\n",
        "    _, reward, _, _ = env.step(action)\n",
        "    N[action] += 1\n",
        "    Q[action] = Q[action] + (reward - Q[action]) / N[action]\n",
        "\n",
        "    Qe[e] = Q\n",
        "    returns[e] = reward\n",
        "    actions[e] = action\n",
        "\n",
        "  return name, returns, Qe, actions"
      ],
      "metadata": {
        "id": "ijt-51WU8PBb"
      },
      "id": "ijt-51WU8PBb",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decaying ϵ-Greedy\n",
        "First maximise exploration, then exploitation.\n",
        "**Note** that in these algorithms, the `decay_ratio` parameter determines the number of episodes that will explore instead of exploit - e.g if `decay_ratio=0.05`, it means the first 5% of the episodes will be used to to decay the epsilon from `init_epsilon` to `min_epsilon`."
      ],
      "metadata": {
        "id": "SKK7DtVx9HKq"
      },
      "id": "SKK7DtVx9HKq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear decaying epsilon greedy\n",
        "class LinearDecayEpsilonGreedy(StrategyBase):\n",
        "  def __init__(self,\n",
        "               env,\n",
        "               init_epsilon=1.0,\n",
        "               min_epsilon=0.01,\n",
        "               decay_ratio=0.05, # the ratio of episodes that will decay eps\n",
        "               n_episodes=5000):\n",
        "    assert init_epsilon>min_epsilon, \"init_epsilon must be greater than min_epsilon\"\n",
        "    super().__init__(f'Lin e-greed {init_epsilon} {min_epsilon} {decay_ratio}',\n",
        "                     env, n_episodes)\n",
        "    self.init_epsilon = init_epsilon\n",
        "    self.min_epsilon = min_epsilon\n",
        "    self.decay_ratio = decay_ratio\n",
        "    self.decay_episodes = max(int(self.n_episodes * self.decay_ratio), 1)\n",
        "    self.delta = (self.init_epsilon-self.min_epsilon) / self.decay_episodes\n",
        "\n",
        "  def run(self):\n",
        "    for e in tqdm(range(self.n_episodes),\n",
        "                  desc=f'Episodes for: {self.name}',\n",
        "                  leave=False):\n",
        "      if e<=decay_episodes:\n",
        "        epsilon = self.init_epsilon - e * self.delta\n",
        "        epsilon = np.clip(epsilon, self.min_epsilon, self.init_epsilon)\n",
        "\n",
        "      if np.random.random() > epsilon:\n",
        "        action = np.argmax(self.Q)\n",
        "      else:\n",
        "        action = np.random.randint(len(self.Q))\n",
        "\n",
        "      self.update(e, action)\n",
        ""
      ],
      "metadata": {
        "id": "WJ_ZvnJ19Qmr"
      },
      "id": "WJ_ZvnJ19Qmr",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponentially decaying epsilon greedy\n",
        "class ExponentialDecayEpsilonGreedy(StrategyBase):\n",
        "  def __init__(self,\n",
        "               env,\n",
        "               init_epsilon=1.0,\n",
        "               min_epsilon=0.01,\n",
        "               decay_ratio=0.1, # the ratio of episodes that will decay eps\n",
        "               n_episodes=5000):\n",
        "    assert init_epsilon>min_epsilon, \"init_epsilon must be greater than min_epsilon\"\n",
        "\n",
        "    super().__init__(f'Exp e-greed {init_epsilon} {min_epsilon} {decay_ratio}',\n",
        "                     env, n_episodes)\n",
        "    self.init_epsilon = init_epsilon\n",
        "    self.min_epsilon = min_epsilon\n",
        "    self.decay_ratio = decay_ratio\n",
        "    decay_episodes = max(int(n_episodes * decay_ratio), 1)\n",
        "    rem_episodes = n_episodes - decay_episodes\n",
        "    eps = np.logspace(np.log10(min_epsilon), np.log10(init_epsilon), decay_episodes)[::-1]\n",
        "    self.epsilons = np.pad(eps, (0, rem_episodes), 'edge')\n",
        "\n",
        "\n",
        "  def run(self):\n",
        "    for e in tqdm(range(self.n_episodes),\n",
        "                  desc=f'Episodes for: {self.name}',\n",
        "                  leave=False):\n",
        "      if np.random.random() > self.epsilons[e]:\n",
        "        action = np.argmax(self.Q)\n",
        "      else:\n",
        "        action = np.random.randint(len(self.Q))\n",
        "\n",
        "      self.update(e, action)"
      ],
      "metadata": {
        "id": "dvOJDMXAdY2U"
      },
      "id": "dvOJDMXAdY2U",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "init_epsilon=1.0\n",
        "min_epsilon=0.01\n",
        "decay_ratio=0.05\n",
        "n_episodes=4\n",
        "\n",
        "eps = []\n",
        "decay_episodes = max(int(n_episodes * decay_ratio), 1)\n",
        "delta = (init_epsilon-min_epsilon) / decay_episodes\n",
        "\n",
        "for e in range(n_episodes):\n",
        "  if e<=decay_episodes:\n",
        "    epsilon = init_epsilon - e*delta\n",
        "    epsilon = np.clip(epsilon, min_epsilon, init_epsilon)\n",
        "  eps.append(epsilon)\n",
        "\n",
        "plt.plot(eps)\n",
        "decay_episodes"
      ],
      "metadata": {
        "id": "ZXcnF3tvWjsH",
        "outputId": "3b39080f-47ea-4ae7-e90f-6f0991fb9eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "id": "ZXcnF3tvWjsH",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_epsilon=1.0\n",
        "min_epsilon=0.01\n",
        "decay_ratio=0.2\n",
        "n_episodes=20\n",
        "\n",
        "decay_episodes = int(n_episodes * decay_ratio)\n",
        "rem_episodes = n_episodes - decay_episodes\n",
        "\n",
        "# epsilons = min_epsilon\n",
        "# epsilons /= np.logspace(np.log10(min_epsilon), np.log10(init_epsilon), decay_episodes)\n",
        "# epsilons *= init_epsilon - min_epsilon\n",
        "# epsilons += min_epsilon\n",
        "epsilons = np.logspace(np.log10(min_epsilon), np.log10(init_epsilon), decay_episodes)[::-1]\n",
        "epsilons = np.pad(epsilons, (0, rem_episodes), 'edge')\n",
        "\n",
        "plt.plot(epsilons)\n",
        "decay_episodes, rem_episodes, epsilons"
      ],
      "metadata": {
        "id": "M2FUMLsJd4uu",
        "outputId": "18cb4823-e79f-4e13-8f73-97bc327b6677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "id": "M2FUMLsJd4uu",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " 16,\n",
              " array([1.        , 0.21544347, 0.04641589, 0.01      , 0.01      ,\n",
              "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
              "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
              "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.logspace(-2, 0, decay_episodes))\n",
        "np.logspace(-2, 0, decay_episodes)"
      ],
      "metadata": {
        "id": "WKT8ldmvrf2X",
        "outputId": "4dbf3ad3-48ca-40d2-84c5-debfe475ab8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "id": "WKT8ldmvrf2X",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01      , 0.04641589, 0.21544347, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}